"use strict";(self.webpackChunkrf_website=self.webpackChunkrf_website||[]).push([[5794],{42773:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>h,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>r,toc:()=>l});var s=t(85893),n=t(11151);const a={title:"Consider Payoff",description:"To work out what to do next, consider the upside and downside risks you're addressing, and also what risks you introduce.",url:"https://riskfirst.org/thinking/Consider-Payoff",featured:{class:"bg3",element:'<image-artifact imgsrc="/public/templates/risk-first/posts/cash.svg">Payoff</image-artifact>'},tags:["Thinking Risk-First","Goal","Attendant Risk","Risk Landscape","Bet","Payoff","Balance Of Risk"],sidebar_position:6,tweet:"yes"},o="Consider Payoff",r={id:"thinking/Consider-Payoff",title:"Consider Payoff",description:"To work out what to do next, consider the upside and downside risks you're addressing, and also what risks you introduce.",source:"@site/docs/thinking/Consider-Payoff.md",sourceDirName:"thinking",slug:"/thinking/Consider-Payoff",permalink:"/thinking/Consider-Payoff",draft:!1,unlisted:!1,editUrl:"https://github.com/risk-first/website/blob/master/docs/thinking/Consider-Payoff.md",tags:[{label:"Thinking Risk-First",permalink:"/tags/thinking-risk-first"},{label:"Goal",permalink:"/tags/goal"},{label:"Attendant Risk",permalink:"/tags/attendant-risk"},{label:"Risk Landscape",permalink:"/tags/risk-landscape"},{label:"Bet",permalink:"/tags/bet"},{label:"Payoff",permalink:"/tags/payoff"},{label:"Balance Of Risk",permalink:"/tags/balance-of-risk"}],version:"current",sidebarPosition:6,frontMatter:{title:"Consider Payoff",description:"To work out what to do next, consider the upside and downside risks you're addressing, and also what risks you introduce.",url:"https://riskfirst.org/thinking/Consider-Payoff",featured:{class:"bg3",element:'<image-artifact imgsrc="/public/templates/risk-first/posts/cash.svg">Payoff</image-artifact>'},tags:["Thinking Risk-First","Goal","Attendant Risk","Risk Landscape","Bet","Payoff","Balance Of Risk"],sidebar_position:6,tweet:"yes"},sidebar:"tutorialSidebar",previous:{title:"Just Risk",permalink:"/thinking/Just-Risk"},next:{title:"Tracking Risks",permalink:"/thinking/Track-Risk"}},h={},l=[{value:"Considering Payoff: Examples",id:"considering-payoff-examples",level:2},{value:"Example 1: YAGNI",id:"example-1-yagni",level:3},{value:"Which is right?",id:"which-is-right",level:4},{value:"Example 2: Do The Simplest Thing That Could Possibly Work",id:"example-2-do-the-simplest-thing-that-could-possibly-work",level:3},{value:"Example 3: Continue Testing or Release?",id:"example-3-continue-testing-or-release",level:3},{value:"What To Do?",id:"what-to-do",level:2}];function d(e){const i={a:"a",blockquote:"blockquote",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,n.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h1,{id:"consider-payoff",children:"Consider Payoff"}),"\n",(0,s.jsx)(i.p,{children:"How do you choose what to work on next?"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"What&#39;s the Payoff",src:t(56934).Z+"",width:"1517",height:"897"})}),"\n",(0,s.jsxs)(i.p,{children:["Sometimes, there will be multiple ",(0,s.jsx)(i.em,{children:"actions"})," you could take on a project and you have to choose the best one:"]}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"There's the risk you'll decide wrongly."}),"\n",(0,s.jsx)(i.li,{children:"And, making a decision takes time, which could add risk to your schedule."}),"\n",(0,s.jsx)(i.li,{children:"And what's the risk if the decision doesn't get made?"}),"\n"]}),"\n",(0,s.jsxs)(i.p,{children:["We can't know in advance how well any action we take will work out.  Therefore, ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#taking-action",children:"Taking Action"})," is a lot like placing a bet."]}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"/thinking/Glossary#payoff",children:"Payoff"})," then is our judgement about whether we expect an action to be worthwhile:  are the risks we escape ",(0,s.jsx)(i.em,{children:"worth"})," the attendant risks we will encounter?  We should be able to ",(0,s.jsx)(i.em,{children:"weigh these separate risks in our hands"})," and judge whether the ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#payoff",children:"Payoff"})," makes a given ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#taking-action",children:"Action"})," worthwhile."]}),"\n",(0,s.jsxs)(i.p,{children:["The fruits of this gambling are revealed when we ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#meet-reality",children:"meet reality"})," and we can see whether our bets were worthwhile."]}),"\n",(0,s.jsx)(i.h2,{id:"considering-payoff-examples",children:"Considering Payoff: Examples"}),"\n",(0,s.jsx)(i.h3,{id:"example-1-yagni",children:"Example 1: YAGNI"}),"\n",(0,s.jsx)(i.p,{children:"As a flavour of what's to come, let's look at YAGNI, an acronym for \"You Aren't Gonna Need It\":"}),"\n",(0,s.jsxs)(i.blockquote,{children:["\n",(0,s.jsxs)(i.p,{children:["YAGNI originally is an acronym that stands for \"You Aren't Gonna Need It\". It is a mantra from Extreme Programming that's often used generally in agile software teams. It's a statement that some capability we presume our software needs in the future should not be built now because \"you aren't gonna need it\".  - ",(0,s.jsxs)(i.a,{href:"https://www.martinfowler.com/bliki/Yagni.html",children:["YAGNI, ",(0,s.jsx)(i.em,{children:"Martin Fowler"})]})]}),"\n"]}),"\n",(0,s.jsxs)(i.p,{children:["The idea makes sense:  if you take on extra work that you don't need, ",(0,s.jsx)(i.em,{children:"of course"})," you'll be accreting risk - you're taking time away from sorting out the real problems!"]}),"\n",(0,s.jsxs)(i.p,{children:["But, there is always the opposite opinion:  ",(0,s.jsxs)(i.a,{href:"http://wiki.c2.com/?YouAreGonnaNeedIt",children:["You ",(0,s.jsx)(i.em,{children:"Are"})," Gonna Need It"]}),".  As a simple example, we often add log statements in our code as we write it (so we can trace what happened when things go wrong), though following YAGNI strictly says we shouldn't."]}),"\n",(0,s.jsx)(i.h4,{id:"which-is-right",children:"Which is right?"}),"\n",(0,s.jsxs)(i.p,{children:["Now, we can say:  do the work ",(0,s.jsxs)(i.em,{children:["if there is a worthwhile ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#payoff",children:"Payoff"})]}),"."]}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["Logging statements are ",(0,s.jsx)(i.em,{children:"good"}),", because otherwise, you're increasing the risk that in production, no one will be able to understand ",(0,s.jsx)(i.em,{children:"how the software went wrong"}),"."]}),"\n",(0,s.jsxs)(i.li,{children:["However, adding them takes time, which might ",(0,s.jsx)(i.a,{href:"/risks/Scarcity-Risk#schedule-risk",children:"risk us not hitting our schedule"}),"."]}),"\n",(0,s.jsxs)(i.li,{children:["Also, we have to manage larger log files on our production systems.  ",(0,s.jsx)(i.em,{children:"Too much logging"})," is just noise, and makes it harder to figure out what went wrong."]}),"\n"]}),"\n",(0,s.jsxs)(i.p,{children:["So, it's a trade-off: continue adding logging statements so long as you feel that overall, the activity ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#payoff",children:"pays off"})," reducing overall risk."]}),"\n",(0,s.jsx)(i.h3,{id:"example-2-do-the-simplest-thing-that-could-possibly-work",children:"Example 2: Do The Simplest Thing That Could Possibly Work"}),"\n",(0,s.jsxs)(i.p,{children:["Another mantra from Kent Beck (originator of the ",(0,s.jsx)(i.a,{href:"https://en.wikipedia.org/wiki/Extreme_programming",children:"Extreme Programming"}),' methodology), is "Do The Simplest Thing That Could Possibly Work", which is closely related to YAGNI and is an excellent razor for avoiding over-engineering.']}),"\n",(0,s.jsx)(i.p,{children:'At the same time, by adding "Could Possibly", Beck is encouraging us to go beyond straightforward iteration and use our brains to pick apart the simple solutions, avoiding them if we can logically determine when they would fail.'}),"\n",(0,s.jsx)(i.p,{children:"Our risk-centric view of this strategy would be:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["Every action you take on a project has its own ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#attendant-risk",children:"Attendant Risks"}),"."]}),"\n",(0,s.jsxs)(i.li,{children:["The bigger or more complex the action, the more ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#attendant-risk",children:"Attendant Risk"})," it'll have."]}),"\n",(0,s.jsxs)(i.li,{children:["The reason you're taking action ",(0,s.jsx)(i.em,{children:"at all"})," is because you're trying to reduce risk elsewhere on the project."]}),"\n",(0,s.jsxs)(i.li,{children:["Therefore, the biggest ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#payoff",children:"Payoff"})," is likely to be the one with the least ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#attendant-risk",children:"Attendant Risk"}),"."]}),"\n",(0,s.jsx)(i.li,{children:"So, usually this is going to be the simplest thing."}),"\n"]}),"\n",(0,s.jsxs)(i.p,{children:['So, "Do The Simplest Thing That Could Possibly Work" is really a helpful guideline for Navigating the ',(0,s.jsx)(i.a,{href:"/risks/Risk-Landscape",children:"Risk Landscape"}),", but this analysis shows clearly where it's left wanting:"]}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.em,{children:"Don't"})," do the simplest thing if there are other things with a better ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#payoff",children:"Payoff"})," available."]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"example-3-continue-testing-or-release",children:"Example 3: Continue Testing or Release?"}),"\n",(0,s.jsx)(i.p,{children:"You're on a project and you're faced with the decision - release now or do more User Acceptance Testing (UAT)?"}),"\n",(0,s.jsxs)(i.p,{children:["Obviously, in the ideal world, we want to get to the place on the ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#risk-landscape",children:"Risk Landscape"})," where we have a tested, bug-free system in production.  But we're not there yet, and we have funding pressure to get the software into the hands of some paying customers.  But what if we disappoint the customers and create bad feeling?   The table below shows an example:"]}),"\n",(0,s.jsxs)(i.table,{children:[(0,s.jsx)(i.thead,{children:(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.th,{children:"Risk Managed"}),(0,s.jsx)(i.th,{children:"Action"}),(0,s.jsx)(i.th,{children:"Attendant Risk"}),(0,s.jsx)(i.th,{children:"Payoff"})]})}),(0,s.jsxs)(i.tbody,{children:[(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"Funding Risk"}),(0,s.jsx)(i.td,{children:(0,s.jsx)(i.strong,{children:"Go Live"})}),(0,s.jsx)(i.td,{children:"Reputational Risk, Operational Risk"}),(0,s.jsx)(i.td,{children:"MEDIUM"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"Implementation Risk"}),(0,s.jsx)(i.td,{children:(0,s.jsx)(i.strong,{children:"Another Round of UAT"})}),(0,s.jsx)(i.td,{children:"Worse Funding Risk, Operational Risk"}),(0,s.jsx)(i.td,{children:"LOW"})]})]})]}),"\n",(0,s.jsxs)(i.p,{children:["This is (a simplification of) the dilemma of lots of software projects - ",(0,s.jsx)(i.em,{children:"test further"}),", to reduce the risk of users discovering bugs (",(0,s.jsx)(i.a,{href:"/risks/Feature-Risk#implementation-risk",children:"Implementation Risk"}),") which would cause us reputational damage, or ",(0,s.jsx)(i.em,{children:"get the release done"})," and reduce our ",(0,s.jsx)(i.a,{href:"/risks/Scarcity-Risk#funding-risk",children:"Funding Risk"})," by getting paying clients sooner."]}),"\n",(0,s.jsxs)(i.p,{children:["In the above table, it ",(0,s.jsx)(i.em,{children:"appears"}),' to be better to do the "Go Live" action, as there is a greater ',(0,s.jsx)(i.a,{href:"/thinking/Glossary#payoff",children:"Payoff"}),".  The problem is, actions are not ",(0,s.jsx)(i.em,{children:"commutative"}),", i.e. the order you do them in counts."]}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"UAT or Go Live: where will you end up?",src:t(77545).Z+"",width:"1297",height:"913"})}),"\n",(0,s.jsxs)(i.p,{children:["The diagram above shows our decision as ",(0,s.jsxs)(i.em,{children:["moves on the ",(0,s.jsx)(i.a,{href:"/thinking/Glossary#risk-landscape",children:"Risk Landscape"})]}),'.  Whether you "Go Live" first, or "UAT" first makes a difference to where you will end up.  Is there a further action you can take to get you from the "Dead End" to the "Goal"?  Perhaps.']}),"\n",(0,s.jsx)(i.h2,{id:"what-to-do",children:"What To Do?"}),"\n",(0,s.jsx)(i.p,{children:"As a concept, payoff is made more tricky because often the actions you take might depend on each other, and the payoff might not be immediate."}),"\n",(0,s.jsxs)(i.p,{children:["So, first things first, you need to make sure you're ",(0,s.jsx)(i.a,{href:"/thinking/Track-Risk",children:"Tracking Risk"})," properly."]})]})}function c(e={}){const{wrapper:i}={...(0,n.a)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},77545:(e,i,t)=>{t.d(i,{Z:()=>s});const s=t.p+"assets/images/risk_landscape_3_moves-f8f76ca828cbeef2b74ef7337cb06cc9.png"},56934:(e,i,t)=>{t.d(i,{Z:()=>s});const s=t.p+"assets/images/payoff-6b83410438f71454106a0d315a69460a.png"},11151:(e,i,t)=>{t.d(i,{Z:()=>r,a:()=>o});var s=t(67294);const n={},a=s.createContext(n);function o(e){const i=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),s.createElement(a.Provider,{value:i},e.children)}}}]);